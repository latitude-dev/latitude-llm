---
title: CrewAI
description: Connect your CrewAI-based application to Latitude Telemetry to observe multi-agent crews and run evaluations.
---

<Note>This integration is only available in the **Python SDK**.</Note>

## Overview

This guide shows you how to integrate **Latitude Telemetry** into an existing application that uses **CrewAI** for building multi-agent systems.

After completing these steps:

- Every CrewAI crew execution can be captured as a log in Latitude.
- Logs are grouped under a **prompt**, identified by a `path`, inside a Latitude **project**.
- You can inspect agent interactions, task execution, and debug CrewAI-powered features from the Latitude dashboard.

<Check>
  You'll keep using CrewAI exactly as you do today — Telemetry simply observes
  and enriches those calls.
</Check>

---

## Requirements

Before you start, make sure you have:

- A **Latitude account** and **API key**
- A **Latitude project ID**
- A Python-based project that uses **CrewAI**

That's it — prompts do **not** need to be created ahead of time.

---

## Steps

<Steps>

  <Step title="Install requirements">
    Add the Latitude Telemetry package to your project:

    <CodeGroup>
      ```bash pip
      pip install latitude-telemetry
      ```

      ```bash uv
      uv add latitude-telemetry
      ```

      ```bash poetry
      poetry add latitude-telemetry
      ```
    </CodeGroup>

  </Step>

  <Step title="Initialize Latitude Telemetry">
    Create a single Telemetry instance when your app starts.

    You must enable the **CrewAI** instrumentor so Telemetry can trace it. Since CrewAI typically uses an LLM provider (like OpenAI), you should also enable that instrumentor.

    ```python telemetry.py
    import os
    from latitude_telemetry import Telemetry, Instrumentors, TelemetryOptions

    telemetry = Telemetry(
        os.environ["LATITUDE_API_KEY"],
        TelemetryOptions(
            instrumentors=[
                Instrumentors.CrewAI,  # This enables automatic tracing for CrewAI
                Instrumentors.OpenAI,  # Also trace the underlying LLM calls
            ],
        ),
    )
    ```

    <Info>
      The Telemetry instance should only be created once. Initialize it before
      importing CrewAI so crew executions are automatically traced.
    </Info>

  </Step>

  <Step title="Wrap your CrewAI-powered feature">
    Wrap the code that runs CrewAI crews using <code>telemetry.capture</code>.

    You can use the `capture` method as a decorator (recommended) or as a context manager:

    ```python Using decorator (recommended)
    from telemetry import telemetry
    from crewai import Agent, Task, Crew

    # Define your agents
    researcher = Agent(
        role="Researcher",
        goal="Research and summarize topics concisely",
        backstory="You are a skilled researcher who provides accurate summaries.",
    )

    writer = Agent(
        role="Writer",
        goal="Write clear and engaging content",
        backstory="You are an experienced writer who creates compelling content.",
    )

    @telemetry.capture(
        project_id=123,  # The ID of your project in Latitude
        path="research-and-write",  # Add a path to identify this prompt in Latitude
    )
    def research_and_write(topic: str) -> str:
        # Define tasks for your crew
        research_task = Task(
            description=f"Research the following topic: {topic}",
            expected_output="A comprehensive summary of the topic.",
            agent=researcher,
        )

        write_task = Task(
            description="Write an article based on the research",
            expected_output="A well-written article.",
            agent=writer,
        )

        # Create and run the crew
        crew = Crew(
            agents=[researcher, writer],
            tasks=[research_task, write_task],
        )

        result = crew.kickoff()

        # You can return anything you want — the value is passed through unchanged
        return result.raw
    ```

    ```python Using context manager
    from telemetry import telemetry
    from crewai import Agent, Task, Crew

    # Define your agents
    researcher = Agent(
        role="Researcher",
        goal="Research and summarize topics concisely",
        backstory="You are a skilled researcher who provides accurate summaries.",
    )

    def research_topic(topic: str) -> str:
        with telemetry.capture(
            project_id=123,  # The ID of your project in Latitude
            path="research-topic",  # Add a path to identify this prompt in Latitude
        ):
            task = Task(
                description=f"Research the following topic: {topic}",
                expected_output="A comprehensive summary.",
                agent=researcher,
            )

            crew = Crew(agents=[researcher], tasks=[task])
            result = crew.kickoff()

            return result.raw
    ```

    <Info>
    The `path`:
    - Identifies the prompt in Latitude
    - Can be new or existing
    - Should not contain spaces or special characters (use letters, numbers, `- _ / .`)
    </Info>

  </Step>

</Steps>

---

## Seeing your logs in Latitude

Once your feature is wrapped, logs will appear automatically.

1. Open the **prompt** in your Latitude dashboard (identified by `path`)
2. Go to the **Traces** section
3. Each execution will show:
   - Input and output messages
   - Agent interactions and task completions
   - Model and token usage from underlying LLM calls
   - Latency and errors
   - One trace per crew execution

Each CrewAI agent execution appears as a child span under the captured prompt execution, giving you a full, end-to-end view of what happened.

---

## That's it

No changes to your CrewAI agents or crews, no special return values, and no extra plumbing — just wrap the feature you want to observe.
