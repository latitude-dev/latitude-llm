---
title: Weather Chatbot
description: Learn how to build a Weather Chatbot using Latitude and custom tools.
---

## Overview

In this example, we will create a Weather Chatbot that can provide weather information based on user queries. The chatbot will use a custom tool to fetch weather data from an external API.

## Prompt

```yaml
---
provider: openai
model: gpt-4o
temperature: 0.2
tools:
  - get_weather:
      description: Fetch weather data for a given location.
      parameters:
        type: object
        properties:
          location:
            type: string
            description: The name of the location to fetch weather data for.
        required:
          - location
---

You are a helpful assistant that can provide weather information.
If the user asks for the weather in a specific location, use the
`get_weather` tool to fetch the data.

<user>
  {{ question }}
</user>
```

## Step-by-step guide

**Related documentation**:
- [Custom Tools](/guides/prompt-manager/tools)
- [SDK](/guides/sdk/typescript)

### Custom Tools

You can create custom tools to extend the capabilities of your chatbot. In this example, we will create a tool that fetches weather data from a public API.

```typescript
function get_weather({ location }: { location: string }) {
  const apiKey = 'your_api_key_here'; // Replace with your actual API key
  const apiUrl = `https://api.openweathermap.org/data/2.5/weather?q=${encodeURIComponent(location)}&appid=${apiKey}`;

  const result = await fetch(apiUrl)
  if (!result.ok) {
    throw new Error(`Error fetching weather data: ${result.statusText}`);
  }

  const data = await result.json();
  return {
    location: data.name,
    temperature: data.main.temp,
    description: data.weather[0].description,
  };
```

This tool fetches weather data from the OpenWeatherMap API based on the provided location. It returns the location name, temperature, and weather description.

### Prompt

Now, let's create a prompt that uses this tool.

First, we need to define the tool structure in the prompt so that the AI model can understand how to use it.

```yaml {5-15}
---
provider: openai
model: gpt-4o
temperature: 0.2
tools:
  - get_weather:
      description: Fetch weather data for a given location.
      parameters:
        type: object
        properties:
          location:
            type: string
            description: The name of the location to fetch weather data for.
        required:
          - location
---
```

Each tool is defined with a name, and must include a `description` and `parameters` following the JSON schema format. Read more about [Tools](/guides/prompt-manager/tools) for more information

Now, we just need to add the prompt instructions!

```yaml {17-24}
---
provider: openai
model: gpt-4o
temperature: 0.2
tools:
  - get_weather:
      description: Fetch weather data for a given location.
      parameters:
        type: object
        properties:
          location:
            type: string
            description: The name of the location to fetch weather data for.
        required:
          - location
---

You are a helpful assistant that can provide weather information.
If the user asks for the weather in a specific location, use the
`get_weather` tool to fetch the data.

<user>
  {{ question }}
</user>
```

### Connecting the prompt with your code

Now, let's run this prompt from your code using your tool!

```typescript {10-12}
const latitude = new Latitude(process.env.LATITUDE_API_KEY, {
  projectId: 123, // Your Latitude project ID
  versionUuid: 'version-uuid', // Optional version UUID
})

const result = await latitude.prompts.run('weather-chatbot', {
  parameters: {
    question: 'What is the weather like in New York?', // Your user's question
  }
  tools: {
    get_weather, // Your custom tool!
  },
})

console.log(result.response.text)
```

### Testing the prompt in the Playground

You tool only lives in your codebase, so it can be run everytime you call your prompt via the SDK! However, from Latitude's Playground we do not have access to your custom tool, so we cannot run it directly. In this case, running the prompt in the Playground will stop and let you add a mocked response for the tool call to test the rest of your prompt.

![Tool Call Request](/assets/playground-tool-call.png)
![Mock Tool Response](/assets/playground-mock-response.png)