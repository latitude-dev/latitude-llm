---
title: 'Chain-of-Thought (CoT)'
description: 'Implement step-by-step reasoning to improve AI performance on complex problems'
---

## What is Chain-of-Thought?

Chain-of-Thought (CoT) prompting is a technique that enhances the reasoning capabilities of Large Language Models by generating intermediate reasoning steps. Instead of jumping directly to an answer, the AI is guided to "think out loud" through each step of the problem-solving process, leading to more accurate and explainable results.

This approach is particularly effective because LLMs often struggle with tasks requiring logical reasoning, mathematical calculations, or multi-step problem solving when they attempt to provide immediate answers.

## Why Use Chain-of-Thought?

### Advantages:
- **Improved Accuracy**: Dramatically reduces errors on complex reasoning tasks
- **Low-Effort Implementation**: Works with off-the-shelf LLMs without fine-tuning
- **Explainable AI**: Users can follow and validate the reasoning process
- **Debugging Capability**: Easy to identify where reasoning went wrong
- **Model Robustness**: Performance remains consistent across different LLM versions
- **Versatile Applications**: Effective for math, logic, code generation, and analysis

### Trade-offs:
- **Higher Token Cost**: More output tokens mean increased API costs
- **Slower Response Time**: Additional reasoning steps take longer to generate
- **Verbosity**: Responses are longer and may require post-processing

## Zero-Shot vs Few-Shot CoT

### Zero-Shot Chain-of-Thought

The simplest form of CoT uses trigger phrases like "Let's think step by step" to encourage reasoning:

<CodeGroup>
```markdown Zero-Shot CoT Example
---
provider: OpenAI
model: gpt-4o
temperature: 0.1
---

# Age Problem Solver

When I was 3 years old, my partner was 3 times my age. Now, I am 20 years old. How old is my partner?

Let's think step by step.
```
</CodeGroup>

**Expected Output:**
```
1. When I was 3 years old, my partner was 3 × 3 = 9 years old
2. The age difference between us is 9 - 3 = 6 years (partner is older)
3. This age difference remains constant over time
4. Now I am 20 years old, so my partner is 20 + 6 = 26 years old

Answer: My partner is 26 years old.
```

### Few-Shot Chain-of-Thought

Providing examples of reasoning improves consistency and teaches the desired thinking pattern:

<CodeGroup>
```markdown Few-Shot CoT Example
---
provider: OpenAI
model: gpt-4o
temperature: 0.1
---

# Age Problem Solver with Examples

Q: When my brother was 2 years old, I was double his age. Now I am 40 years old. How old is my brother? Let's think step by step.

A: When my brother was 2 years old, I was 2 × 2 = 4 years old. That's an age difference of 4 - 2 = 2 years, and I am older. Now I am 40 years old, so my brother is 40 - 2 = 38 years old. The answer is 38.

Q: When I was 3 years old, my partner was 3 times my age. Now, I am 20 years old. How old is my partner? Let's think step by step.

A: [Let the AI complete this using the pattern from the example]
```
</CodeGroup>

## Common Failure Patterns

### Without CoT (Problematic):
```
Prompt: When I was 3 years old, my partner was 3 times my age. Now, I am 20 years old. How old is my partner?
Output: 63 years old ❌
```

### With CoT (Improved):
```
Prompt: [Same question] Let's think step by step.
Output: [Step-by-step reasoning leading to] 26 years old ✅
```

## When to Use Chain-of-Thought

CoT is particularly effective for tasks that benefit from explicit reasoning:

### Ideal Use Cases:
- **Mathematical Problems**: Arithmetic, algebra, geometry calculations
- **Code Generation**: Breaking down requirements into implementable steps
- **Logical Reasoning**: Puzzles, deduction, inference problems
- **Synthetic Data Creation**: Guided assumption-making and content generation
- **Complex Analysis**: Multi-factor decision making, comparative analysis
- **Process Planning**: Step-by-step procedure development

### Decision Rule:
> **If you can explain the steps to solve the problem manually, CoT will likely improve AI performance.**

## Effective CoT Trigger Phrases

Different trigger phrases work better for different types of problems:

<CodeGroup>
```markdown CoT Triggers
---
provider: OpenAI
model: gpt-4o
temperature: 0.1
---

# Mathematical/Logical Problems
"Let's think step by step."
"Let's work through this systematically."
"Let's break this down into steps."

# Analysis Tasks
"Let's analyze this carefully."
"Let's examine each component."
"Let's think through the implications."

# Creative/Planning Tasks
"Let's approach this methodically."
"Let's consider each aspect."
"Let's build this solution piece by piece."

# Code Generation
"Let's implement this step by step."
"Let's break down the requirements first."
"Let's design the solution systematically."

Problem: {{ user_problem }}

{{ trigger_phrase }}
```
</CodeGroup>

## Practical CoT Examples

### Synthetic Data Generation with CoT

<CodeGroup>
```markdown Synthetic Data CoT
---
provider: OpenAI
model: gpt-4o
temperature: 0.3
---

# Product Description Generator

Product: {{ product_name }}

Let's create a compelling product description by thinking through this step by step:

Step 1: Analyze the product name
- What type of product does this suggest?
- What market segment would this target?
- What key features can we infer?

Step 2: Make reasonable assumptions
- Who is the target customer?
- What problems does this solve?
- What are the key selling points?

Step 3: Structure the description
- Opening hook to grab attention
- Key features and benefits
- Social proof or credibility elements
- Call to action

Step 4: Write the description
Based on my analysis and assumptions:
```
</CodeGroup>

### Mathematical Problem Solving

<CodeGroup>
```markdown Advanced Math CoT
---
provider: OpenAI
model: gpt-4o
temperature: 0.1
---

# Word Problem Solver

Problem: {{ math_word_problem }}

Let me solve this step by step:

Step 1: Extract the key information
- What quantities are given?
- What relationships exist between them?
- What am I asked to find?

Step 2: Set up the mathematical model
- Define variables for unknown quantities
- Write equations based on the relationships
- Identify the mathematical operations needed

Step 3: Solve systematically
- Perform calculations in logical order
- Show each algebraic step
- Check intermediate results

Step 4: Verify and interpret
- Does the answer make logical sense?
- Does it satisfy the original constraints?
- Express the final answer clearly

Solution:
```
</CodeGroup>

## Advanced CoT with Latitude Chains

LLM perform better when they can reason through complex problems step by step. In the case of Latitude `<step>` blocks what they do is to call the AI only with the content inside the `<step>` block, so the AI can focus on that specific part of the reasoning process. This allows for more structured and manageable reasoning.

<Note>
  Doing this way is more expensive than a single prompt, but it allows for more complex reasoning and better results. Is more expensive because it does N calls to the AI, where N is the number of `<step>` blocks. And the amount of context of the steps is accumulated, so the AI can use all the context of the previous steps.
</Note>
<CodeGroup>
```markdown Multi-Step CoT Chain
---
provider: OpenAI
model: gpt-4o
temperature: 0.2
---

<step>
# Step 1: Problem Analysis

Let's analyze this business scenario step by step: {{ business_scenario }}

## Initial Assessment:
1. **Key Stakeholders**: Who are the main parties involved?
2. **Core Problem**: What is the fundamental issue?
3. **Constraints**: What limitations do we need to consider?
4. **Success Metrics**: How will we measure success?

## Analysis:
</step>

<step>
# Step 2: Solution Brainstorming

Based on my analysis: {{ problem_analysis }}

Now let me generate potential solutions:

## Brainstorming Process:
1. **Traditional Approaches**: What are the conventional solutions?
2. **Innovative Options**: What creative alternatives exist?
3. **Resource Requirements**: What would each solution need?
4. **Risk Assessment**: What are the potential downsides?

## Potential Solutions:
</step>

<step>
# Step 3: Solution Evaluation

Given these potential solutions: {{ solution_brainstorming }}

Let me evaluate each option systematically:

## Evaluation Criteria:
1. **Feasibility** (1-10): How realistic is implementation?
2. **Impact** (1-10): How effective will this be?
3. **Cost** (1-10): How resource-efficient is this? (10 = low cost)
4. **Timeline** (1-10): How quickly can this be implemented? (10 = very fast)

## Solution Rankings:
</step>

<step>
# Step 4: Implementation Planning

Based on the evaluation: {{ solution_evaluation }}

The recommended solution is: [Top-ranked solution]

## Implementation Plan:
1. **Phase 1** (Weeks 1-2): [Initial steps]
2. **Phase 2** (Weeks 3-4): [Development phase]
3. **Phase 3** (Weeks 5-6): [Testing and refinement]
4. **Phase 4** (Weeks 7-8): [Full implementation]

## Risk Mitigation:
- **Risk 1**: [Potential issue] → **Mitigation**: [How to address]
- **Risk 2**: [Potential issue] → **Mitigation**: [How to address]

## Success Metrics:
- **Short-term** (1 month): [Immediate indicators]
- **Medium-term** (3 months): [Progress markers]
- **Long-term** (6+ months): [Ultimate success measures]
</step>
```
</CodeGroup>

## CoT for Different Domains

### Scientific Analysis

<CodeGroup>
```markdown Scientific CoT
---
provider: OpenAI
model: gpt-4o
temperature: 0.1
---

# Scientific Method with Chain-of-Thought

Apply the scientific method to analyze: {{ research_question }}

## Step 1: Observation and Question Formation
- **Observation**: What have we observed?
- **Research Question**: What specific question are we trying to answer?
- **Background**: What do we already know about this topic?

## Step 2: Hypothesis Development
- **Hypothesis**: What do we predict will happen?
- **Reasoning**: Why do we think this will occur?
- **Variables**: What factors might influence the outcome?

## Step 3: Experimental Design
- **Method**: How would we test this hypothesis?
- **Controls**: What variables need to be controlled?
- **Measurements**: What data would we collect?

## Step 4: Data Analysis Framework
- **Expected Results**: What patterns would support our hypothesis?
- **Alternative Explanations**: What other factors could explain results?
- **Statistical Considerations**: How would we ensure reliability?

## Step 5: Conclusion and Implications
- **Interpretation**: What would different results mean?
- **Limitations**: What are the constraints of this approach?
- **Next Steps**: How would this lead to further research?

## Analysis:
[Apply this framework to the given research question]
```
</CodeGroup>

### Legal Reasoning

<CodeGroup>
```markdown Legal CoT
---
provider: OpenAI
model: gpt-4o
temperature: 0.1
---

# Legal Analysis with Chain-of-Thought

Analyze this legal scenario step by step: {{ legal_scenario }}

## Step 1: Fact Pattern Analysis
- **Key Facts**: What are the essential facts?
- **Parties Involved**: Who are the relevant parties?
- **Timeline**: What is the sequence of events?
- **Jurisdiction**: What legal system applies?

## Step 2: Legal Issue Identification
- **Primary Issues**: What are the main legal questions?
- **Secondary Issues**: What related questions arise?
- **Precedent Relevance**: What similar cases might apply?

## Step 3: Rule Identification
- **Applicable Laws**: What statutes or regulations apply?
- **Case Law**: What precedents are relevant?
- **Legal Standards**: What tests or criteria apply?

## Step 4: Application of Law to Facts
- **Element Analysis**: How do the facts satisfy each legal element?
- **Counterarguments**: What opposing positions exist?
- **Distinguishing Cases**: How is this different from precedents?

## Step 5: Conclusion and Reasoning
- **Legal Conclusion**: What is the most likely outcome?
- **Strength of Position**: How strong is each side's case?
- **Risk Assessment**: What are the uncertainties?

## Analysis:
[Apply this legal reasoning framework]
```
</CodeGroup>

## CoT with Self-Correction

<CodeGroup>
```markdown Self-Correcting CoT
---
provider: OpenAI
model: gpt-4o
temperature: 0.3
---

<step>
# Initial Reasoning Attempt

Problem: {{ complex_problem }}

Let me work through this step by step:

1. **Understanding**: [Break down the problem]
2. **Approach**: [Choose a method]
3. **Execution**: [Work through the solution]
4. **Result**: [State the initial answer]

Initial Solution:
</step>

<step>
# Self-Critique and Error Checking

Let me review my initial reasoning: {{ initial_reasoning }}

## Error Checking:
1. **Logic Verification**: Are my reasoning steps sound?
2. **Calculation Check**: Are my computations correct?
3. **Assumption Review**: What assumptions did I make?
4. **Alternative Approaches**: Could I solve this differently?

## Potential Issues Found:
- [List any problems identified]

## Confidence Level**: [High/Medium/Low] because [reasoning]
</step>

<step>
# Revised Solution (if needed)

Based on my self-critique

If the initial reasoning had issues, let me correct it:
## Corrections Made:
1. **Issue**: [Problem identified]
   **Correction**: [How I fixed it]

## Revised Step-by-Step Solution:
[Work through the corrected solution]

## Final Answer: [Corrected result]

Otherwise, confirm the original reasoning:
## Confirmation:
My initial reasoning appears sound. The original answer stands.

## Final Answer: [Original result confirmed]
</step>
```
</CodeGroup>

## CoT with Multiple Perspectives

<CodeGroup>
```markdown Multi-Perspective CoT
---
provider: OpenAI
model: gpt-4o
temperature: 0.4
type: agent
agents:
  - agents/analyst_a
  - agents/analyst_b
  - agents/synthesizer
---

# Multi-Perspective Analysis

Analyze this complex issue: {{ complex_issue }}

Use multiple analytical perspectives and then synthesize the findings.

## Analysis Framework:

### Perspective A: {{ perspective_a_description }}
- Apply this analytical lens step by step
- Focus on {{ perspective_a_focus }}

### Perspective B: {{ perspective_b_description }}
- Apply this different analytical approach
- Emphasize {{ perspective_b_focus }}

### Synthesis:
- Compare and contrast the perspectives
- Identify points of agreement and disagreement
- Develop a comprehensive understanding

Coordinate the analysis across agents and provide a unified conclusion.
```

```markdown agents/analyst_a
---
provider: OpenAI
model: gpt-4o
temperature: 0.2
type: agent
---

# Perspective A Analysis: {{ perspective_a_description }}

I'll analyze the issue through this specific lens: {{ complex_issue }}

## Step-by-Step Analysis:

1. **Framework Application**: How does {{ perspective_a_description }} apply here?
2. **Key Factors**: What elements are most important from this perspective?
3. **Methodology**: What analytical tools should I use?
4. **Evidence Gathering**: What information supports this view?
5. **Reasoning Chain**: How do these factors connect?
6. **Conclusions**: What does this perspective suggest?

## Detailed Analysis:
[Work through each step systematically]

## Key Insights from Perspective A:
- [Primary findings]
- [Supporting evidence]
- [Implications]
```
</CodeGroup>

## Integration with Latitude Features

### CoT with Dynamic Variables

<CodeGroup>
```markdown Dynamic CoT
---
provider: OpenAI
model: gpt-4o
temperature: 0.2
---

# Adaptive Chain-of-Thought

The reasoning approach adapts based on the problem type: {{ problem_type }}

{{ if problem_type === "mathematical" }}
  ## Mathematical Problem-Solving Steps:
  1. **Parse the Problem**: Extract numbers, operations, and relationships
  2. **Identify the Method**: Choose appropriate mathematical approach
  3. **Set Up Equations**: Translate word problem to mathematical expressions
  4. **Solve Step-by-Step**: Show all algebraic manipulations
  5. **Verify**: Check answer by substitution or alternative method
{{ endif }}


{{ if problem_type === "analytical" }}
  ## Analytical Reasoning Steps:
  1. **Decompose**: Break complex issue into component parts
  2. **Research**: Gather relevant information and context
  3. **Framework**: Apply appropriate analytical model
  4. **Synthesize**: Combine insights from different sources
  5. **Conclude**: Draw evidence-based conclusions
{{ endif }}

{{ if problem_type === "creative" }}
  ## Creative Problem-Solving Steps:
  1. **Understand**: Deeply comprehend the challenge
  2. **Diverge**: Generate multiple creative options
  3. **Combine**: Mix and match ideas innovatively
  4. **Evaluate**: Assess feasibility and impact
  5. **Refine**: Improve the most promising solutions
{{ endif }}

## Problem to Solve:
{{ user_problem }}

## Step-by-Step Solution:
[Apply the appropriate framework above]
```
</CodeGroup>

### CoT with Tool Integration

<CodeGroup>
```markdown CoT with Tools
---
provider: OpenAI
model: gpt-4o
temperature: 0.2
tools:
  - latitude/search
  - latitude/extract
---

# Research-Enhanced Chain-of-Thought

Let me solve this complex question step by step: {{ research_question }}

## Step 1: Information Gathering
First, I need to research the current facts:

## Step 2: Information Analysis
Based on the search results, let me analyze:
- **Key Facts**: [Extract relevant information]
- **Data Quality**: [Assess reliability of sources]
- **Gaps**: [Identify missing information]

## Step 3: Additional Research (if needed)
Extract specific data that is still unclear or missing.

## Step 4: Reasoning Chain
Now I'll work through the logic:
1. **Given Information**: [Summarize what we know]
2. **Logical Connections**: [Show how facts relate]
3. **Inference Steps**: [Build the argument]
4. **Supporting Evidence**: [Reference research findings]

## Step 5: Conclusion
Based on this systematic analysis:
[Present final answer with full reasoning]
```
</CodeGroup>

## Best Practices

<AccordionGroup>
<Accordion title="Choosing the Right CoT Approach">
**Zero-Shot CoT**: Use simple trigger phrases like "Let's think step by step" for straightforward problems
**Few-Shot CoT**: Provide examples when you need consistent reasoning patterns or specific approaches
**Multi-Step Chains**: Use Latitude `<step>` blocks for complex problems requiring focused attention on each phase
**Cost Consideration**: Balance reasoning quality with token costs - more steps = better results but higher costs
</Accordion>

<Accordion title="Effective Prompt Design">
**Clear Step Labels**: Use numbered steps or clear headers to guide reasoning
**Logical Flow**: Ensure each step builds logically on the previous one
**Explicit Instructions**: Always include trigger phrases to activate reasoning mode
**Verification Steps**: Include self-checking and validation mechanisms
**Domain-Specific Language**: Use terminology and approaches familiar to the problem domain
</Accordion>

<Accordion title="Optimizing Performance">
**Model Selection**: Use GPT-4 or Claude for complex reasoning tasks
**Temperature Settings**: Lower temperature (0.1-0.3) for logical/mathematical problems
**Token Management**: Balance reasoning detail with cost efficiency
**Error Handling**: Include correction and retry mechanisms
**Robustness**: CoT helps maintain performance across different LLM versions
</Accordion>

<Accordion title="Domain-Specific Adaptations">
**Mathematical Problems**: Focus on step-by-step calculations and verification
**Code Generation**: Break down requirements before implementation
**Scientific Analysis**: Emphasize hypothesis formation and testing
**Business Decisions**: Include stakeholder analysis and risk assessment
**Creative Tasks**: Allow for iterative refinement and exploration
</Accordion>

<Accordion title="Cost-Benefit Analysis">
**When CoT is Worth It**: Complex reasoning, high-stakes decisions, mathematical problems
**When to Avoid**: Simple factual queries, high-volume/low-cost applications
**Optimization**: Use shorter reasoning chains for simpler problems
**Monitoring**: Track accuracy improvements vs. cost increases
</Accordion>
</AccordionGroup>

## Common Pitfalls

<Warning>
**Critical Mistakes to Avoid**:

**Reasoning Errors**:
- **Skipping Logical Steps**: Don't let the AI jump to conclusions without showing work
- **Unclear Transitions**: Make connections between steps explicit and logical
- **Missing Verification**: Always include checking mechanisms and validation steps
- **Assuming Expertise**: Remember that LLMs can make confident but incorrect mathematical errors

**Implementation Issues**:
- **Over-complexity**: Keep steps manageable - too many steps can confuse the model
- **Inconsistent Patterns**: When using few-shot, ensure examples follow the same reasoning structure
- **Wrong Trigger Phrases**: Some phrases work better for different problem types
- **Ignoring Context**: Make sure reasoning steps are appropriate for the problem domain

**Cost Management**:
- **Unnecessary Verbosity**: Don't use CoT for simple factual queries that don't need reasoning
- **Excessive Steps**: More steps aren't always better - find the right balance
- **Poor Token Planning**: Account for the 2-3x token increase when budgeting
</Warning>

## When NOT to Use CoT

CoT isn't always the best approach. Avoid it for:

- **Simple Factual Queries**: "What is the capital of France?" doesn't need reasoning steps
- **High-Volume Applications**: When processing thousands of requests where cost matters more than reasoning
- **Well-Defined Formats**: When you need consistent, structured outputs without explanation
- **Time-Sensitive Tasks**: When response speed is more important than reasoning quality
- **Retrieval Tasks**: When the answer exists in a knowledge base and doesn't require reasoning

## Implementation Checklist

When implementing CoT in your prompts, use this checklist:

### ✅ Pre-Implementation
- Confirm the task benefits from step-by-step reasoning
- Choose appropriate CoT type (zero-shot vs few-shot vs multi-step)
- Select effective trigger phrases for your domain
- Plan for increased token costs (typically 2-3x)

### ✅ Prompt Design
- Include clear step labels and logical flow
- Add verification/checking steps
- Provide examples if using few-shot approach
- Test with edge cases and failure scenarios

### ✅ Optimization
- Adjust temperature based on task type (lower for logic/math)
- Monitor accuracy improvements vs cost increases
- Iterate on step structure based on results
- Consider using Latitude `<step>` blocks for complex reasoning

## Key Takeaways

Chain-of-Thought prompting transforms how LLMs approach complex problems by making their reasoning explicit and systematic. Here are the essential points:

**Core Benefits:**
- **Dramatic accuracy improvements** on reasoning tasks without model fine-tuning
- **Explainable results** that allow debugging and validation
- **Robust performance** across different LLM versions

**Best Applications:**
- Mathematical and logical problems
- Code generation with requirement breakdown
- Complex analysis requiring multiple perspectives
- Any task where you can explain the solution steps manually

**Cost Considerations:**
- 2-3x more tokens means higher costs and slower responses
- Use strategically for high-value, complex reasoning tasks
- Consider simpler approaches for basic queries

**Implementation Success Factors:**
- Choose the right CoT variant (zero-shot, few-shot, or multi-step)
- Use domain-appropriate trigger phrases and terminology
- Include verification steps to catch reasoning errors
- Balance reasoning depth with practical constraints

Chain-of-Thought is a low-effort, high-impact technique that can significantly improve AI performance on complex tasks. The key is knowing when and how to apply it effectively.

## Advanced CoT Patterns

### CoT with Error Correction

<CodeGroup>
```markdown Self-Correcting CoT
---
provider: OpenAI
model: gpt-4o
temperature: 0.2
---

# Problem Solving with Validation

Problem: {{ complex_problem }}

## Initial Reasoning
Let me work through this step by step:

1. **Understanding**: [Break down the problem]
2. **Approach**: [Choose methodology]
3. **Execution**: [Show work]
4. **Initial Answer**: [State result]

## Self-Validation
Now let me check my work:

1. **Logic Check**: Are my reasoning steps sound?
2. **Calculation Verification**: Let me double-check any math
3. **Sanity Test**: Does this result make intuitive sense?
4. **Alternative Approach**: Can I solve this differently to confirm?

## Final Answer
Based on validation: [Confirmed or corrected result]
```
</CodeGroup>

### CoT with Confidence Scoring

<CodeGroup>
```markdown Confidence-Aware CoT
---
provider: OpenAI
model: gpt-4o
temperature: 0.1
---

# Reasoning with Confidence Assessment

Problem: {{ problem_statement }}

## Step-by-Step Analysis
[Standard CoT reasoning steps]

## Confidence Assessment
For each step, I'll rate my confidence (1-10):

- **Step 1 Confidence**: 9/10 - Clear factual information
- **Step 2 Confidence**: 7/10 - Some assumptions required
- **Step 3 Confidence**: 8/10 - Standard methodology applied
- **Overall Confidence**: 8/10

## Risk Factors
- **Potential Issues**: [What could go wrong]
- **Missing Information**: [What would improve confidence]
- **Alternative Scenarios**: [Other possible outcomes]

## Conclusion
Answer: [Result] (Confidence: X/10)
```
</CodeGroup>

## Next Techniques

Explore these related prompting techniques:
- [Tree of Thoughts](/examples/techniques/tree-of-thoughts) - Explore multiple reasoning paths
- [Self-Consistency](/examples/techniques/self-consistency) - Multiple CoT attempts with voting
- [Few-shot Learning](/examples/techniques/few-shot-learning) - CoT with examples
- [Constitutional AI](/examples/techniques/constitutional-ai) - Self-correcting reasoning
