---
title: Prompt Suggestions
description: Use automatically generated suggestions based on evaluation results to improve your prompts.
---

Latitude's Prompt Suggestions feature (known as the Refiner) analyzes your evaluation results to automatically recommend improvements for your prompts. It acts like an AI assistant helping you iterate faster and achieve better performance.

## How Suggestions Are Generated

1.  **Data Collection**: The system gathers results from your completed evaluations ([LLM-as-Judge](/guides/evaluations/llm-as-judges), [Programmatic Rules](/guides/evaluations/programmatic_rules), and [Manual Evaluations](/guides/evaluations/humans-in-the-loop)). Both batch and live evaluation results are considered.
2.  **Pattern Analysis**: Latitude analyzes these results, looking for correlations between prompt inputs, outputs, and evaluation scores. It identifies patterns where certain inputs lead to lower scores or specific failure modes.
3.  **Suggestion Generation**: Based on these patterns, an AI model generates concrete suggestions for modifying your prompt. These suggestions might involve:
    - Rewording instructions for clarity.
    - Adding context or constraints.
    - Providing better examples (few-shot learning).
    - Adjusting prompt structure.
    - Modifying [configuration parameters](/guides/prompt-manager/configuration).
4.  **Prioritization**: Suggestions are often prioritized based on the potential impact on evaluation scores.

<Note>
  Suggestions become more insightful as more evaluation data is collected. Aim
  for at least 20-30 evaluated logs for meaningful analysis, though more data is
  generally better.
</Note>

## Viewing and Applying Suggestions

1.  **Navigate to the Prompt**: Open the prompt you want to improve in the editor.
2.  **Check for Suggestions**: If suggestions are available, a "Suggestions" button/indicator will appear at the bottom of the prompt editor.
    ![Suggestions Indicator](/assets/prompt_suggestions_indicator.png)
3.  **Review Suggestions**: Clicking the button opens a panel displaying the generated suggestions. Each suggestion includes:
    - The reasoning based on evaluation data (e.g., "Outputs often failed the 'Conciseness' evaluation for long inputs").
    - Clicking the "View" button will display a diff of the proposed changes to the current prompt.
      ![Suggestions View](/assets/prompt_suggestions_view.png)
4.  **Apply or Dismiss**: For each suggestion, you can:
    - **Apply**: Automatically applies the suggested change to your current prompt draft.
    - **Dismiss**: Ignores the suggestion.
      ![Suggestions Diff](/assets/prompt_suggestions_diff.png)

## Next Steps

- Ensure you have robust [Evaluations](/guides/evaluations/overview) set up.
- Regularly [Run Evaluations](/guides/evaluations/running-evaluations) to feed the Refiner.
- Learn about preparing data with [Datasets](/guides/datasets/overview).
