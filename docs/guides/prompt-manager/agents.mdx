---
title: Agents
description: Create autonomous agents that can use tools, reason, and complete complex tasks over multiple steps.
---

<iframe
  width='100%'
  height='500px'
  src='https://www.youtube.com/embed/d77AGdOYpVA?si=DS-21MrIICHbbS9T'
  title='Latitude Agents Overview'
  frameborder='0'
  allow='accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share'
  referrerpolicy='strict-origin-when-cross-origin'
  allowfullscreen
></iframe>

Latitude Agents are an advanced prompt type that enables AI models to operate autonomously, breaking down complex tasks, using tools, and reasoning through multiple steps until a final goal is achieved.

Unlike simple prompts or even [Chains](/promptl/advanced/chains) which follow predefined steps, Agents can dynamically decide their next action based on the context and available tools.

## Defining an Agent

To turn a prompt into an Agent, simply add `type: agent` to its configuration block:

```markdown {4}
---
provider: openai
model: gpt-4o
type: agent
---

Plan and execute the steps needed to research and write
a short blog post about the benefits of using Latitude Agents.
```

## How the Agent Loop Works

When an Agent prompt is run:

1.  **Goal Understanding**: The agent analyzes the initial prompt to understand the overall task or goal.
2.  **Planning (Implicit)**: It internally plans the first step needed to move towards the goal.
3.  **Action**: It decides whether to:
    a. **Call a Tool**: If it needs external information or functionality, it requests a tool call.
    b. **Generate Response**: If it has enough information or needs to ask a clarifying question, it generates text.
4.  **Observation**: If a tool was called, it receives the tool's response.
5.  **Reasoning**: Based on the goal, previous steps, and new observations (tool responses), it reasons about the next action needed.
6.  **Repeat**: Steps 3-5 repeat until the agent determines the original goal is fully accomplished.
7.  **Final Answer**: The agent provides the final result.

This loop allows the agent to adapt its strategy, handle errors, and utilize tools effectively.

## Using Tools Within Agents

Agents become truly powerful when combined with [Tools](/guides/prompt-manager/tools). Provide the agent with a set of relevant tools, and it will decide which ones to use and when.

```markdown
---
provider: openai
model: gpt-4o
type: agent
tools:
  - latitude/search
  - get_weather
  - get_location_id

  # Tool definitions...
  - get_weather:
      # ... definition
  - get_location_id:
      # ... definition
---

Find the current weather for {{ location_name }}.
```

In this example, the agent might:

1.  Realize it needs a location ID for `get_weather`.
2.  Call `get_location_id` with `location_name`.
3.  Receive the `location_id`.
4.  Call `get_weather` with the obtained `location_id`.
5.  Receive the weather data.
6.  Formulate and return the final answer to the user.

## Defining the Final Output (Schema)

You can guide the agent's final output by specifying a response `schema` using [JSON Schema](/guides/prompt-manager/json-output):

```markdown
---
provider: openai
model: gpt-4o
type: agent
tools:
  - latitude/search
schema:
  type: object
  properties:
    summary:
      type: string
      description: A concise summary of the findings.
    key_points:
      type: array
      items:
        type: string
      description: A list of key bullet points.
  required: [summary, key_points]
---

Research the main features of the Vercel AI SDK and provide a summary and key bullet points.
```

The agent will work towards fulfilling the task and then structure its final response according to the schema.

## Predefined Steps

While agents operate autonomously, you can provide initial instructions or force specific actions using `<step>` tags. The agent will execute these predefined steps first before entering its autonomous loop.

```markdown
---
# ... agent config ...
---

<step>
  First, search for recent news about AI advancements.
</step>

<step>
  Then, identify the top 3 trends mentioned.
</step>

Now, write a short analysis comparing these trends.
```

## Limiting Agent Iterations

To prevent agents from running indefinitely (e.g., getting stuck in loops), you can limit the maximum number of steps (tool calls + LLM responses) using the `maxSteps` configuration option (default: 20, max: 150).

```yaml
---
# ... agent config ...
maxSteps: 10 # Limit the agent to 10 steps
---
```

If the limit is reached before the goal is completed, the agent run will terminate with an error.

## Running Agents

Agents are run just like any other prompt using the [API](/guides/api/api-access) or [SDKs](/guides/sdk/typescript). The response will typically be a stream of events detailing the agent's thought process, tool calls, and final answer.

## Subagents

You can make any prompt have access to other agents in your project by using the `agents` configuration option. This allows you to create a hierarchy of agents, where tasks are delegated to subagents with specific responsibilities.

```yaml {4-5}
---
provider: openai
model: gpt-4o
agents:
 - path/to/another-agent
---
```

The main prompt will have access to running the subagent prompt as if it was a tool. This allows you to structure complex tasks into smaller, manageable sub-tasks performed by different agents.

## Next Steps

- Explore [Latitude Tools](/guides/prompt-manager/latitude-tools) that agents can use.
- Test your agents in the [Playground](/guides/prompt-manager/playground).
- Learn about [Evaluations](/guides/evaluations/overview) to assess agent performance.
