---
title: API Access
description: Learn how to access and use Latitude's API to run your prompts.
---

We recommend checking the SDK docs section in case you're looking for a specific language or framework.

## Latitude HTTP API Documentation

This guide explains how to use the Latitude HTTP API to interact with the Prompt Manager and run AI-powered conversations.

### Authentication

All API requests require authentication. Include your API key in the `Authorization` header of your HTTP requests:

```
Authorization: Bearer YOUR_API_KEY
```

### Base URL

The base URL for API requests depends on your environment:

`https://gateway.latitude.so/api/v2`

### Rate Limiting

The API enforces rate limits based on your API key to ensure fair usage and prevent abuse.

**Limits:**

- **Rate Limit Points:** 1000 requests
- **Rate Limit Duration:** 60 seconds

When the rate limit is exceeded, the following headers are included in the response to help you manage your request rate:

- `Retry-After`: Indicates the number of seconds to wait before making a new request.
- `X-RateLimit-Limit`: The maximum number of requests allowed in the current period.
- `X-RateLimit-Remaining`: The number of requests remaining in the current period.
- `X-RateLimit-Reset`: The timestamp when the rate limit will reset.

**Example Headers:**

```http
Retry-After: 60
X-RateLimit-Limit: 1000
X-RateLimit-Remaining: 999
X-RateLimit-Reset: 1729399082482
```

These headers are sent with every request to help you monitor and adjust your request rate accordingly.

### Endpoints

#### 1. Run a Document

Run a specific document (prompt) with optional parameters.

**Endpoint:** `POST /projects/{projectId}/versions/{versionUuid}/documents/run`

**Path Parameters:**

- `projectId`: Your project ID (required)
- `versionUuid`: Version UUID (optional, defaults to 'live')

**Request Body:**

```json
{
  "path": "path/to/document",
  "parameters": {
    "key1": "value1",
    "key2": "value2"
  },
  "stream": false
}
```

- `stream`: Optional boolean parameter (defaults to `false`). When set to true, the response will be a stream of Server-Sent Events (SSE). If false, a single JSON response containing the last event is returned.

**Response:**

- If `stream` is `true`: The response is a stream of Server-Sent Events (SSE). Each event contains JSON data with the following structure:

```json
{
  "type": "chain-step" | "chain-step-complete" | "chain-complete",
  "isLastStep": boolean,
  "uuid": string,
  "config": {
    "provider": string,
    "model": string
  },
  "messages": Message[],
  "response": {
    "text": string,
    "toolCalls": ToolCall[],
    "usage": {
      "promptTokens": number,
      "completionTokens": number,
      "totalTokens": number
    }
  }
}
```

- If `stream` is `false`: A single JSON response is returned with the final event (typically the chain-complete event) in the following structure:

```json
{
  "uuid": string,
  "conversation": Message[],
  "response": {
    "streamType": "text" | "object",
    "usage": {
      "promptTokens": number,
      "completionTokens": number,
      "totalTokens": number
    },
    "text": string,
    "object": object | undefined,
    "toolCalls": ToolCall[]
}
```

<Note>
  Message follows [OpenAI's format](https://platform.openai.com/docs/guides/text-generation/building-prompts).
</Note>

<Note>
ToolCall has the following format:

```typescript
type ToolCall = {
  id: string
  name: string
  arguments: Record<string, unknown>
}
```
</Note>

#### 2. Chat

The previously described `POST /projects/{projectId}/versions/{versionUuid}/documents/run` endpoint can also be used to continue a conversation. Notice all events contain a `uuid` field that represents that conversation with the AI. You can use this uuid to continue the conversation.

**Endpoint:** `POST /conversations/{conversationUuid}/chat`

**Path Parameters:**

- `conversationUuid`: UUID of the conversation

**Request Body:**

```json
{
  "messages": [
    {
      "role": "user" | "system" | "assistant",
      "content": string
    }
  ],
  "stream": true
}
```

- `stream`: Optional boolean parameter (defaults to `false`). When set to true, the response will be a stream of Server-Sent Events (SSE). If false, a single JSON response containing the last event is returned.

<Note>
  Message follows [OpenAI's format](https://platform.openai.com/docs/guides/text-generation/building-prompts).
</Note>

**Response:**
The response is a stream of Server-Sent Events (SSE) or a single JSON response containing the final event, similar to the "Run a Document" endpoint.

#### 3. Get a Prompt

Retrieve a specific prompt by its path.

**Endpoint:** `GET /projects/{projectId}/versions/{versionUuid}/documents/{documentPath}`

**Path Parameters:**

- `projectId`: Your project ID (required)
- `versionUuid`: Version UUID (optional, defaults to 'live')
- `documentPath`: Path to the document (required)

**Request Headers:**

Include your API key in the `Authorization` header of your HTTP requests:

```
Authorization: Bearer YOUR_API_KEY
```

**Response:**

The response contains the document details along with its configuration.

**Response Body:**

```json
{
  "id": "document-id",
  "name": "Document Name",
  "content": "Document content",
  "path": "path/to/document",
  "resolvedContent": "Compiled document content (might be nil)",
  "contentHash": "Document content hash (might be nil)",
  "commitId": "Commit ID",
  "deletedAt": "Deleted at timestamp (might be nil)",
  "createdAt": "Created at timestamp",
  "updatedAt": "Updated at timestamp",
  "config": "Document frontmatter configuration (might be nil)",
}

### Handling Server-Sent Events (SSE)

The API uses SSE for real-time updates. Here's how to handle SSE responses:

1. Set up an EventSource or use a library that supports SSE.
2. Listen for events and parse the JSON data in each event.
3. Handle different event types:
   - `latitude-event`: Contains information about the chain progress and results.
   - `provider-event`: Contains real-time updates from the AI provider.

### Error Handling

The API uses standard HTTP status codes. In case of an error, the response body will contain an error message:

```json
{
  "error": {
    "message": "Error description"
  }
}
```

3. #### Get a Document

Retrieve a specific prompt by its path.

**Endpoint:** `GET /projects/{projectId}/versions/{versionUuid}/documents/{path}`

**Path Parameters:**

- `projectId`: Your project ID (required)
- `versionUuid`: Version UUID (optional, defaults to 'live')
- `path`: Path to the document (required)

**Request Headers:**

Include your API key in the `Authorization` header of your HTTP requests:

```
Authorization: Bearer YOUR_API_KEY
```

**Response:**

The response contains the document details along with its configuration.

**Response Body:**

```json
{
  "id": "document-id",
  "name": "Document Name",
  "content": "Document content",
  "config": {
    "provider": "Provider name",
    "model": "Model name"
  }
}
```

**Example Request:**

```bash
curl -X GET "https://gateway.latitude.so/api/v2/projects/123/versions/live/documents/path/to/document" \
     -H "Authorization: Bearer YOUR_API_KEY"
```

**Example Response:**

```json
{
  "id": "document-id",
  "name": "Document Name",
  "content": "Document content",
  "config": {
    "provider": "Provider name",
    "model": "Model name"
  }
}
```

#### 4. Evaluate a Conversation

Evaluate a conversation using configured evaluations.

**Endpoint:** `POST /conversations/{conversationUuid}/evaluate`

**Path Parameters:**

- `conversationUuid`: UUID of the conversation to evaluate

**Request Body:**

```json
{
  "evaluationUuids": ["evaluation-uuid-1", "evaluation-uuid-2"] // optional, defaults to all evaluations connected to the conversation prompt
}
```

**Response:**

```json
{
  "evaluations": ["evaluation-uuid-1", "evaluation-uuid-2"] // array of evaluation UUIDs that will be run
}
```
